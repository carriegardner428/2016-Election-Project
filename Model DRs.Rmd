---
title: "ModelDRs"
output: html_document
---

```{r setup, include=FALSE}
library(plyr)     # for recoding data
library(NLP)      # for NLP
library(tm)       # for Corpus()
library(e1071)    # svm
library(rpart)    # decision trees
library(ada)      # for adaboost
library(lsa)
library(NMF)
library(caret)
library(Matrix)
library(SparseM)
library(caret)
```

# Helper Functions
```{r}
load.data.DR <- function() {
  # preprocessed in python
  tweets = read.csv('DR_users.csv') # data is preprocessed in python
  tweets = tweets[,-1]
  tweets[1:3,]
  table(tweets$party) # D:881, R:383
  
  tweets$text = as.character(tweets$text)
  tweets$state_code = as.character(tweets$state_code)
  
  # Recode Dems = 0, Reps = 1
  tweets$party = revalue(tweets$party, c("D"=0, "R"=1))
  any(is.na(tweets$party))

  tweets[1:3,]
  return(tweets)
}

# Return reusable model of training data
model.fit <- function(X_train, y_train, classifier) {
   switch(classifier, 
        nb = {
          model = naiveBayes(x=X_train, y=y_train)
          # y_predictions = predict(model, newdata=X_test)
         },
         dtree = {
          # model = rpart(y~., data=train, method="class")
          model = rpart(y_train~X_train, method="class")
          y_predictions = predict(model, newdata=X_test)
         },
        svmradial = {
          X_train = as.matrix.csr(X_train)  # 1,244
          # X_test  = as.matrix.csr(X_test)    # 622
          model = svm(X_train, y_train, kernel="radial")
          # y_predictions = predict(model, newdata=X_test)
        },
        svmlinear = {
          X_train = as.matrix.csr(X_train)  # 1,244
          # X_test  = as.matrix.csr(X_test)    # 622
          model = svm(X_train, y_train, kernel="linear")
          # y_predictions = predict(model, newdata=X_test)
        },
        rf = {
          obs = nrow(X_train)
          X_train2 = create_container(X_train, y_train, trainSize = 1:obs, virgin=FALSE)
          model = train_model(X_train2, "RF")
          y_predictions = predict(model, newdata=X_test)  
        },
        gbm = {
          library(caret)
          model = train(X_train, y_train, method="gbm", verbose=FALSE)
          y_predictions = predict(model, newdata=X_test)
        },
        tune = {
          params = expand.grid(interaction.depth = c(1, 5, 9),
                               n.trees = (1:30)*50,
                               n.minobsinnode = 20)
          nrow(params)
          model = train(X_train, y_train, method="adaboost")
                        #verbose = FALSE, 
                        #tuneGrid = params)
        },
        test = {
          dim(X_train)
          data.pca = prcomp(X_train, scale=FALSE)
          # summary(data.pca)
          # Find first 750 PCs
          train<-data.pca$x[,1:10]
          dim(train)
          
          train = cbind(train, y_train)
          colnames(train)[ncol(train)] = 'y'
          train = as.data.frame(train)
          train$y = as.factor(train$y)
          
          model = train(y~., data=train, method="adaboost")
          
          model = naiveBayes(y~., data=train)
          y_predictions = predict(model, newdata=X_test)
          
          y_predictions =  
          
        
        }
        
   )
  return(model)
}

# Return predictions of y_test
model.predict <- function(X_test, model) {
  X_test = as.data.frame(X_test)
  y_predictions = predict(model, newdata=X_test)
  # if probabilties
  ## probs = predict(model, newdata=X_test)
  ## y_predictions = as.numeric(probs > .50)
  return(y_predictions)
}

# Find Precision, Recall, and F Score
model.evaluate <- function(y_predictions, y_test) {
  Precision = posPredValue(y_predictions, y_test)
  Recall    = sensitivity(y_predictions, y_test)
  F1 = (2 * precision * recall) / (precision + recall)
  
  # bind values together
  #rownames(col) = c("Precision", "Recall", "F1")
  col = rbind(Precision, Recall, F1)
  return(col)
}

# Cross Validate
crossValidate <- function(document_term_matrix, y, classifier, k.fold=3) {
  eval = matrix(, nrow = 3, ncol = 0)
  n.obs = nrow(document_term_matrix) # no. of observations 
  n.obs
  s = sample(n.obs)
  s
  k = 1
  k.fold = 3
  for (k in 1:k.fold) {
    test.idx = which(s %% k.fold == (k-1) ) # use modular operator
    X_train = as.matrix(document_term_matrix[-test.idx,])  # 1,244
    X_test  = as.matrix(document_term_matrix[test.idx,])    # 622
    y_train = y[-test.idx]                      # 1,244
    y_test  = y[test.idx]                        # 622
    # model 
    model = model.fit(X_train, y_train, classifier)
    y_predictions = model.predict(X_test, model)
    # evaluate predictions -- obtain precision, recall, F1 score
    k.eval = model.evaluate(y_predictions, y_test)
    eval = cbind(eval, k.eval)
    eval
  }
  # return table of K fold precision, recall, fscore 
  colnames(eval) = c("Fold 1", "Fold 2", "Fold 3")
  eval
  return(eval)
}

```

# Load Data & Create DTMs
```{r }
user.tweets = load.data.DR()

# Get corpus
user.corpus = Corpus(VectorSource(user.tweets$text))

# Get DTM, and TFIDF Dtm, and labels (y)
document_term_matrix = DocumentTermMatrix(user.corpus)
dtm.tfidf = DocumentTermMatrix(user.corpus, control = list(weighting=weightTfIdf))
y = user.tweets$party

# Get reduced DTMs
## PCA, LSA, 
dtm.pca = do.pca(dtm) # 1264, 1264; Matrix object
dtm.lsa.10 = do.lsa(dtm.tfidf, ndims=10) # 1264, 10; Matrix object
dtm.mds = do.mds(dtm)

## Drop unused rows


### Drop rows where TfIdf weight == 0
row.totals = apply(dtm, 1, sum)
length(row.totals)
length(y)

dim(dtm)
dtm.new = dtm[row.totals > 0, ]
y.new   = y[row.totals > 0]
length(y.new) # 1264
dim(dtm.new)# dim 1264, 11897


dim(dtm) # doc, terms


do.lsa <- function(dtm.tfidf, ndims=10) {
  S = svd(dtm.tfidf, nu = ndims, nv = ndims)
  dtm.lsa = S$u
  return(dtm.lsa)
}

do.pca <- function(dtm) {
  pca = prcomp(dtm, scale=FALSE)
  dtm.pca = predict(pca) # 1264, 1264
  return(dtm.pca)
}

do.mds <- function(dtm) {
  dtm = as.matrix(dtm)
  dtm.dist = dist(t(dtm))
  dtm.mds = cmdscale(dtm.dist, k=2)
  return(dtm.mds)
}
```

# Run Cross Validation
#### Features: Standard DTM, TFIDF DTM, LSA DTM, PCA DTM, and MDS DTM
#### Classifiers: Naive Bayes, SVM-Radial Kernel, SVM-Linear Kernel

## Standard Document Term Matrix
```{r }
# Standard Document Term Matrix
### Classifiers - NB, SVMRadial, SVMLinear
dtm.eval.nb = crossValidate(document_term_matrix, y, 'nb')
dtm.eval.svmradial = crossValidate(document_term_matrix, y, 'svmradial')
dtm.eval.svmlinear = crossValidate(document_term_matrix, y, 'svmlinear')

```
## TFIDF Document Term Matrix
```{r }
# TFIDF Weighted Document Term Matrix
### Classifiers - NB, SVMRadial, SVMLinear
tfidf.eval.nb = crossValidate(dtm.tfidf, y, 'nb')
tfidf.eval.svmradial = crossValidate(dtm.tfidf, y, 'svmradial')
tfidf.eval.svmlinear = crossValidate(dtm.tfidf, y, 'svmlinear')
```

## LSA DTM
```{r }
# LSA Document Term Matrix
### Classifiers - NB, SVMRadial, SVMLinear
lsa.eval.nb = crossValidate(dtm.tfidf, y, 'nb')
lsa.eval.svmradial = crossValidate(dtm.tfidf, y, 'svmradial')
lsa.eval.svmlinear = crossValidate(dtm.tfidf, y, 'svmlinear')

```






