---
title: "OpenNLP"
author: "Carrie Gardner"
date: "4/15/2017"
output: html_document
---

```{r setup, include=FALSE}
library(plyr)     # for recoding data
library(NLP)      # for NLP
library(tm)       # for Corpus()
library(e1071)    # svm
library(rpart)    # decision trees
library(ada)      # for adaboost
library(SnowballC)
library(lsa)
library(NMF)
library(rJava)
library(openNLP)
library(NLP)  
library(RWeka)
library(magrittr)
library(caret)
library(Matrix)
library(SparseM)
```


```{r }
set.seed(1000)

load.data <- function() {

  user.tweets = read.csv('tweets_by_user.csv')
  users.party = read.csv('users.csv')
  
  user.tweets[1:3,]
  users.party[1:3,]
  
  data = merge(user.tweets, users.party, by=('userID'))
  data[1:3,]
  
    # if NAs exist, drop rows
  if (any(is.na(data))) {
    data = na.omit(data)
  }
  
  # Collapse parties
  table(data$party)
  data$party[data$party=="G"] = "I"
  data$party[data$party=="O"] = "I"
  data$party[data$party=="L"] = "I"
  table(data$party)
  
  dim(data) # 1,866 users (w/o party NAs)
  
# Change variable types to characters
  data$text = as.character(data$text)
  data$party = as.character(data$party)
  
  # Show data
  data[1:3,]
  return (data)
}

load.data.DR <- function() {
  # preprocessed in python
  tweets = read.csv('DR_users.csv')
  tweets = tweets[,-1]
  tweets[1:3,]
  table(tweets$party) # D:881, R:383
  
  tweets$text = as.character(tweets$text)
  tweets$state_code = as.character(tweets$state_code)
  
  # Recode Dems = 0, Reps = 1
  tweets$party = revalue(tweets$party, c("D"=0, "R"=1))
  any(is.na(tweets$party))

  tweets[1:3,]
  return(tweets)
}


# Clean corpus
do.preprocess <- function(corpus, removeSparseTerms=FALSE) {
  # lowercase
  corpus = tm_map(corpus, content_transformer(tolower))
  # remove stops, punctuation, numbers, whitespaces; 

  # Remove everything besides english letters or space
  remov = function(x) gsub("[^[:alpha:][:space:]]*", "", x)
  corpus <- tm_map(corpus, content_transformer(remov))
  
  # remove URLs & @ mentions
  removeURL = function(x) gsub("http[^[:space:]]*", "", x)
  removeMention = function(x) gsub("@[:alpha][space:]]*", "", x)
  corpus = tm_map(corpus, removeURL)
  corpus = tm_map(corpus, removeMention)
  
  myStops = c(stopwords("english"), "https", "http", "debate", "debatenight", "debate night")
  corpus = tm_map(corpus, removeWords, myStops)
  corpus = tm_map(corpus, stripWhitespace)
  
  ## Optional - remove sparse terms
  if (removeSparseTerms) {
    corpus = tm_map(corpus, removeSparseTerms)
  }
  

  # stem
  # corpus = tm_map(corpus, stemDocument)
  
  return (corpus)
}
```

```{r}
# Return reusable model of training data
model.fit <- function(X_train, y_train, classifier) {
   switch(classifier, 
        nb = {
          model = naiveBayes(x=X_train, y=y_train)
          # y_predictions = predict(model, newdata=X_test)
         },
         dtree = {
          model = rpart(y_train~X_train, method="class")
          y_predictions = predict(model, newdata=X_test)
         },
        svmradial = {
          X_train = as.matrix.csr(X_train)  # 1,244
          # X_test  = as.matrix.csr(X_test)    # 622
          model = svm(X_train, y_train, kernel="radial")
          # y_predictions = predict(model, newdata=X_test)
        },
        svmlinear = {
          X_train = as.matrix.csr(X_train)  # 1,244
          # X_test  = as.matrix.csr(X_test)    # 622
          model = svm(X_train, y_train, kernel="linear")
          # y_predictions = predict(model, newdata=X_test)
        },
        rf = {
          obs = nrow(X_train)
          X_train2 = create_container(X_train, y_train, trainSize = 1:obs, virgin=FALSE)
          model = train_model(container, "RF")
          y_predictions = predict(model, newdata=X_test)  
        }
   )
  return(model)
}

# Return predictions of y_test
model.predict <- function(X_test, model) {
  y_predictions = predict(model, newdata=X_test)
  # if probabilties
  ## probs = predict(model, newdata=X_test)
  ## y_predictions = as.numeric(probs > .50)
  return(y_predictions)
}

model.evaluate <- function(y_predictions, y_test) {
  Precision = posPredValue(y_predictions, y_test)
  Recall = sensitivity(y_predictions, y_test)
  F1 = (2 * precision * recall) / (precision + recall)
  
  # bind values together
  #rownames(col) = c("Precision", "Recall", "F1")
  col = rbind(Precision, Recall, F1)
  return(col)
}

crossValidate <- function(document_term_matrix, y, classifier, k.fold=3) {
  eval = matrix(, nrow = 3, ncol = 0)
  n.obs = nrow(document_term_matrix) # no. of observations 
  n.obs
  s = sample(n.obs)
  s
  # k = 1
  # k.fold = 3
  for (k in 1:k.fold) {
    test.idx = which(s %% k.fold == (k-1) ) # use modular operator
    X_train = as.matrix(document_term_matrix[-test.idx,])  # 1,244
    X_test  = as.matrix(document_term_matrix[test.idx,])    # 622
    y_train = y[-test.idx]                      # 1,244
    y_test  = y[test.idx]                        # 622
    # model 
    model = model.fit(X_train, y_train, classifier)
    y_predictions = model.predict(X_test, model)
    # evaluate predictions -- obtain precision, recall, F1 score
    k.eval = model.evaluate(y_predictions, y_test)
    eval = cbind(eval, k.eval)
    eval
  }
  # return table of K fold precision, recall, fscore 
  colnames(eval) = c("Fold 1", "Fold 2", "Fold 3")
  eval
  return(eval)
}


```

```{r }
# Tweets by User
user.tweets = load.data()
user.tweets = load.data.DR()
```

```{r }
# User.tweets is a dataframe of unique users and a string of all of their tweets 
user.tweets[1:3,]
dim(user.tweets) # 1,866 users

# Get corpus
user.corpus = Corpus(VectorSource(user.tweets$text))
inspect(user.corpus[1:3])

# Preprocess corpus (lowercase; remove stops, punctuation, numbers, whitespaces; stem)
user.corpus = do.preprocess(user.corpus)
inspect(user.corpus[1:3])

# Get Document Term Matrix
document_term_matrix = DocumentTermMatrix(user.corpus)
dim(document_term_matrix) # 1,866 observations / 1,264
y = user.tweets$party
length(y)                 # 1,866 observations / 1,264

# Classifiers
## nb, svm, svmsig
eval.nb  = crossValidate(document_term_matrix, y, classifier = 'nb')
eval.nb

eval.svmradial = crossValidate(document_term_matrix, y, 'svmradial')
eval.svmradial

eval.svmsig = crossValidate(document_term_matrix, y, 'svmsig')
eval.svmsig
```


