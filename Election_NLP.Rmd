---
title: "2016 Election"
author: "Carrie Gardner"
date: "3/29/2017"
output: html_document
---

```{r warning=FALSE, message=FALSE}
library(plyr)     # for recoding data
library(ggplot2)  # for plotting
library(NLP)      # for NLP
library(tm)       # for Corpus()
library(SnowballC)
library(lsa)
library(NMF)
```

##### Helper functions
```{r Helper }
set.seed(1000)

# Ingest datasets and cleans data
load.data.task <- function() {
  data.path = "user_setA/"
  
  data.files = c('tweets_debate1.csv', 'tweets_debate2.csv',
                 'tweets_debate3.csv', 'tweets_debateVP.csv')
  data.tweets = do.call(rbind,lapply(data.files, function(f) {
                            read.csv(f)
                })
         )
  
  data.users = read.csv('users.csv')
  
  data.tweets[1:3,]
  data.users[1:3,]
  data = merge(data.tweets, data.users, by=('userID'))
  
  data[1:3,]
  
  dim(data) # 60,378 observations
  # if NAs exist, drop rows
  if (any(is.na(data))) {
    data = na.omit(data)
  }
  dim(data) # now 38,044 observations
  
# Change variable types to characters
  data$text = as.character(data$text)
  data$party = as.character(data$party)
  
  # Show data
  data[1:3,]
  return (data)
}

# Plot Topic Histogram
do.topic_histo <- function(data) {
  ggplot(data, aes(x=factor(party), fill=party)) + 
    geom_bar(stat="count") + 
    scale_x_discrete("Party") + 
    scale_y_continuous("Frequency") + 
    scale_fill_manual(values=c('blue', 'green', 'purple', 'yellow', 'orange', 'red')) + 
    ggtitle("Party Frequency") +
    coord_flip()
}

# subset data and pull out Democrats, Republicans, and Independents
#### NEED TO UPDATE
get.subdoc <- function(data, toptopics=4) {
  selected_topics = sort(table(data$Topic), decreasing = T)[1:toptopics]
  selected_topics = names(selected_topics)
  selected_topics
  
  doc_idx = which(data$Topic %in% selected_topics)
  subdoc = data[doc_idx,]
  return(subdoc)
}

# Clean corpus
do.preprocess <- function(corpus, stem=FALSE, removeSparseTerms=FALSE) {
  # lowercase
  corpus = tm_map(corpus, content_transformer(tolower))
  # remove stops, punctuation, numbers, whitespaces; 
  corpus = tm_map(corpus, function(x) removeWords(x, stopwords("english")))
  corpus = tm_map(corpus, removePunctuation)
  corpus = tm_map(corpus, removeNumbers)
  corpus = tm_map(corpus, stripWhitespace)
  ## Optional - remove sparse terms
  if (removeSparseTerms) {
    corpus = tm_map(corpus, removeSparseTerms)
  }
  # stem
  if (stem) {
    corpus = tm_map(corpus, stemDocument, language = "english")
  }
  return (corpus)
}

# NMF
do.nmf <- function(tdm) {
  nmf.res = nmf(tdm, 3, "lee")
  # estimate target matrix
  v.hat = fitted(nmf.res)
  # w = n * r term feature matrix
  w = basis(nmf.res)
  h = coef(nmf.res)
  return(h)
}

do.mds <- function(tdm) {
  # compute distance matrix
  tdm = as.matrix(tdm)
  tdm.dist = dist(t(tdm)) 
  tdm.mds = cmdscale(tdm.dist, k = 2)
  
  return(tdm.mds)
}

```

# Read in data 
# Examine class Distribution
```{r }
data = load.data.task()
dim(data)

do.topic_histo(data)

## Since the data is heavily unbalanced, perhaps we should randomly remove some Democrats?
```

Collapse Other, Libertarian Party, and Green Party into Independent category.

```{r}
table(data$party)

data$party[data$party=="G"] = "I"
data$party[data$party=="O"] = "I"
data$party[data$party=="L"] = "I"

table(data$party)

ggplot(data, aes(x=factor(party), fill=party)) + 
    geom_bar(stat="count") + 
    scale_x_discrete("Party") + 
    scale_y_continuous("Frequency") + 
    scale_fill_manual(values=c('blue', 'purple','red')) + 
    ggtitle("Party Frequency") +
    coord_flip()
  
# Plot Topic Histogram
do.topic_histo <- function(data) {

}

```

## Word Cloud
#### Reference: https://www.r-bloggers.com/building-wordclouds-in-r/
```{r}
library(wordcloud)
library(RColorBrewer)
corpus = Corpus(VectorSource(data$text))

corpus = do.preprocess(corpus, stem=FALSE)
inspect(corpus[100:300])

# Make Term Document Matrix (tdm)
tdm = TermDocumentMatrix(corpus)

wordcloud(corpus, max.words = 100, random.order = FALSE)
wordcloud(corpus, max.words = 100, random.order = FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(corpus, max.words = 100, random.order = FALSE, colors="Purple")

```

## Extract Hashtags

```{r}
library(stringr)

tweets = data$text

hashtags = str_exract_all(data$text, "#\\S+")

str_extract_all("Hello peopllz! My new home is #crazy gr8! #wow", "#\\S+")



```
# Question 2
```{r }
# Get corpus subset
# subdoc = get.subdoc(data, toptopics=4)   # subset the data to find top 4 categories

data$text
corpus = Corpus(VectorSource(data$text))

inspect(corpus[1:3])

# Preprocess corpus (lowercase; remove stops, punctuation, numbers, whitespaces; stem)
corpus = do.preprocess(corpus)
inspect(corpus[100:300])
corpus

# Make Term Document Matrix (tdm)
tdm = TermDocumentMatrix(corpus)

# Extact terms w/frequency >= 4
term.freq = findFreqTerms(tdm, 4)
tdm.index = which(row.names(tdm) %in% term.freq)
tdm = tdm[tdm.index,]
dim(tdm)

findFreqTerms(tdm, 50)

# Calculate MDS
doc.mds = do.mds(tdm)

# Plot MDS
data = data.frame(x = doc.mds[, 1], 
                  y = doc.mds[, 2], 
                  Party = data$party, 
                  id = row.names(data) )
ggplot(data, aes(x = x , y = y, color = Party)) + 
  geom_point(shape = 1) +
  ggtitle("MDS Plot")
```

# Question 3
```{r T1Q3}
################################################
# TF-IDF
tfidf.tdm = as.matrix(tdm)

# TF-IDF weighting
tfidf.weights = lw_tf(tfidf.tdm) * gw_idf(tfidf.tdm)

# Calculate TF-IDF MDS
tfidf.mds = do.mds(tfidf.weights)

# Plot TF-IDF MDS
tfidf.data = data.frame(x = tfidf.mds[, 1], 
                  y = tfidf.mds[, 2], 
                  Topic = subdoc$Topic, 
                  id = row.names(subdoc) )

ggplot(tfidf.data, aes(x = x , y = y, color = Topic)) + 
  geom_point(shape = 1) +
  ggtitle("MDS Plot - TF-IDF")

################################################
# LSA
lsa.space = lsa(tfidf.weights, dims = 4)

# Calculate LSA MDS
lsa.dist.mat = dist(t(as.textmatrix(lsa.space)))
lsa.mds = cmdscale(lsa.dist.mat, k = 2)

# Plot LSA MDS
lsa.data = data.frame(x = lsa.mds[, 1], 
                      y = lsa.mds[, 2], 
                      Topic = subdoc$Topic, 
                      id = row.names(subdoc))

ggplot(lsa.data, aes(x = x, y = y, color = Topic)) + 
  geom_point(shape = 1) +
  ggtitle("MDS Plot - LSA")


################################################
# NMF
tdm = as.matrix(tdm)
h = do.nmf(tdm)

# Calculate NMF MDS
nmf.mds = do.mds(h)

# Plot NMF MDS 
nmf.data = data.frame(x = nmf.mds[, 1], 
                      y = nmf.mds[, 2], 
                      Topic = subdoc$Topic, 
                      id = row.names(subdoc))

ggplot(nmf.data, aes(x = x, y = y, color = Topic)) + 
  geom_point(shape = 1) +
  ggtitle("MDS Plot - NMF")
```

```{r }
# Model & Get Probabilties
do.classification <- function(train.set, test.set, 
                              cl.name, verbose=T) {
  ## Return raw probabilties to plot ROC later
  switch(cl.name, 
         knn3 = { # k = 3
           prob = knn(train.set[,-1], test.set[,-1], cl=train.set[,1], k = 3, prob=T)
           attr(prob,"prob")[prob==0] = 1-attr(prob,"prob")[prob==0]
           prob = attr(prob,"prob")
           prob
         },
         knn5 = { # k = 5
           prob = knn(train.set[,-1], test.set[,-1], cl=train.set[,1], k = 5, prob=T)
           attr(prob,"prob")[prob==0] = 1-attr(prob,"prob")[prob==0]
           prob = attr(prob,"prob")
           prob
         },
         knn7 = { # k = 7
           prob = knn(train.set[,-1], test.set[,-1], cl=train.set[,1], k = 7, prob=T)
           attr(prob,"prob")[prob==0] = 1-attr(prob,"prob")[prob==0]
           prob = attr(prob,"prob")
           prob
         },
         knn9 = { # k = 9
           prob = knn(train.set[,-1], test.set[,-1], cl=train.set[,1], k = 9, prob=T)
           attr(prob,"prob")[prob==0] = 1-attr(prob,"prob")[prob==0]
           prob = attr(prob,"prob")
           prob
         },
         glm = { # logistic regression
           model = glm(y~., family=binomial, data=train.set)
           if (verbose) {
             print(summary(model))             
           }
           prob = predict(model, newdata=test.set, type="response") 
           prob
         },
         nb = { # naive bayes
           model = naiveBayes(y~., data=train.set)
           prob = predict(model, newdata=test.set, type="raw") 
           prob = prob[,2]/rowSums(prob) # renormalize the probabilites.
           prob
         },
         dtree = {  # decision tree
           model = rpart(y~., data=train.set)
           print(summary(model))  # detailed summary of splits
           printcp(model)         # print the cross-validation results
           plotcp(model)          # visualize the cross-validation results
           # plot the tree
           plot(model, uniform=TRUE, main="Decision Tree")
           text(model, use.n=TRUE, all=TRUE, cex=.8)
           prob = predict(model, newdata=test.set)
           prob = prob[,2]/rowSums(prob) # renormalize the prob.
           prob
         },
         prunedTree = { # pruned decision tree
           model = rpart(y~., data=train.set)
           if (verbose) {
             print(summary(model))  # detailed summary of splits
             printcp(model)         # print the cross-validation results
             plotcp(model)          # visualize the cross-validation results
             # plot the tree
             plot(model, uniform=TRUE, main="Pruned Decision Tree")
             text(model, use.n=TRUE, all=TRUE, cex=.8)
           }
           prob = predict(model, newdata=test.set)
           if (1) { # pruned tree
             # prune the tree
             pfit<- prune(model, cp=model$cptable[which.min(model$cptable[,"xerror"]),"CP"])
             prob = predict(pfit, newdata=test.set)
             # plot the pruned tree
             plot(pfit, uniform=TRUE,main="Pruned Decision Tree")
             text(pfit, use.n=TRUE, all=TRUE, cex=.8)
           }
           prob = prob[,2]/rowSums(prob) # renormalize the prob.
           prob
         },
         svm_radial = {
           model = svm(y~., data=train.set, probability=T)
           if (0) { # kernel = radial
             # gamma = 10^(-6:-1)
             # cost  = 10^(-1:1)
             tuned <- tune.svm(y~., data = train.set, 
                               kernel="radial", 
                               gamma = 10^(-6:-1), cost = 10^(-1:1))
             #print(summary(tuned))
             gamma = tuned[['best.parameters']]$gamma
             cost = tuned[['best.parameters']]$cost
             model = svm(y~., data = train.set, probability=T, 
                         kernel="radial", gamma=gamma, cost=cost)                        
           }
           prob = predict(model, newdata=test.set, probability=T)
           prob = attr(prob,"probabilities")
           # print(dim(prob))
           prob = prob[,which(colnames(prob)==1)]/rowSums(prob)
           # prob
         },
         svm = {
           model = svm(y~., data=train.set, probability=T)
           prob = predict(model, newdata=test.set, probability=T)
           prob = attr(prob,"probabilities")
           prob = cbind(prob,as.character(test.set$y))
           prob = prob[,which(colnames(prob)==1)]/rowSums(prob)
           prob
         },
         svm_sigmoid = {
           model = svm(y~., data=train.set, probability=T)
           if (1) { # kernel = sigmoid
             # gamma = 10^(-6:-1)
             # cost  = 10^(-1:1)
             tuned <- tune.svm(y~., data = train.set,
                               kernel="sigmoid",
                               gamma = 10^(-6:-1), cost = 10^(-1:1))
             #print(summary(tuned))
             gamma = tuned[['best.parameters']]$gamma
             cost = tuned[['best.parameters']]$cost
             model = svm(y~., data = train.set, probability=T,
                         kernel="radial", gamma=gamma, cost=cost)
           }
           prob = predict(model, newdata=test.set, probability=T)
           prob = attr(prob,"probabilities")
           # print(dim(prob))
           print(prob)
           prob
           # prob = prob[,which(colnames(prob)==1)]/rowSums(prob)
           # prob
         },
         svm_poly = {
           model = svm(y~., data=train.set, probability=T)
           if (1) { # kernel = polynomial
             # gamma = 10^(-6:-1)
             # cost  = 10^(-1:1)
             tuned <- tune.svm(y~., data = train.set,
                               kernel="polynomial",
                               gamma = 10^(-6:-1), cost = 10^(-1:1))
             #print(summary(tuned))
             gamma = tuned[['best.parameters']]$gamma
             cost = tuned[['best.parameters']]$cost
             model = svm(y~., data = train.set, probability=T,
                         kernel="radial", gamma=gamma, cost=cost)
           }
           prob = predict(model, newdata=test.set, probability=T)
           prob = attr(prob,"probabilities")
           # print(dim(prob))
           prob = prob[,which(colnames(prob)==1)]/rowSums(prob)
           # prob
         },
         ada = {
           model = ada(y~., data = train.set)
           prob = predict(model, newdata=test.set, type='probs')
           prob = prob[,2]/rowSums(prob)
           # prob
         }
  ) 
  return (prob)
}

# Run 10-fold Cross Validation
k.fold.cv <- function(dataset, cl.name, k.fold=10, prob.cutoff=0.5, evaluate = FALSE) {
  ## default: 10-fold CV, cut-off 0.5
  n.obs <- nrow(dataset) # no. of observations
  s = sample(n.obs)
  errors = dim(k.fold)
  precisions = dim(k.fold)
  recalls = dim(k.fold)
  fscores = dim(k.fold)
  accuracies = dim(k.fold)
  probs = NULL
  actuals = NULL
  for (k in 1:k.fold) {
    test.idx = which(s %% k.fold == (k-1) ) # use modular operator
    train.set = dataset[-test.idx,]
    test.set = dataset[test.idx,]
    cat(k.fold,'-fold CV run',k,cl.name,':',
        '#training:',nrow(train.set),
        '#testing',nrow(test.set),'\n')
    prob = do.classification(train.set, test.set, cl.name)
    predicted = as.numeric(prob > prob.cutoff)
    actual = test.set$y
    confusion.matrix = table(actual, factor(predicted,levels=c(0,1))) # confusion matrix
    
    TP = confusion.matrix[2,2] # if "1" is positive
    TN = confusion.matrix[1,1] # if "0" is negative
    FP = confusion.matrix[1,2]
    FN = confusion.matrix[2,1]
    
    precision = TP/(FP+TP)
    recall = TP/(FN+TP)
    fscore = 2/(1/precision + 1/recall)
    error = (FP + FN) / nrow(test.set)
    errors[k] = error
    cat('\t\terror=',error,'\n')
    
    accuracy = 1 - error
    
    precisions[k] = precision
    recalls[k] = recall
    fscores[k] = fscore
    probs = c(probs,prob)
    actuals = c(actuals,actual)
  }
  avg.error = mean(errors)
  cat('avg error=',avg.error,'\n')
  avg.accuracy = 1 - avg.error
  cat('avg Accuracy=',avg.accuracy,'\n')
  avg.precision = mean(precisions)
  cat('avg Precision=',avg.precision,'\n')
  avg.recall = mean(recalls)
  cat('avg recall=',avg.recall,'\n')
  avg.fscore = mean(fscores)
  cat('avg fscore=',avg.fscore,'\n')
  
  ## plot ROC
  result = data.frame(probs,actuals)
  pred = prediction(result$probs,result$actuals)
  perf = performance(pred, "tpr","fpr")
  auc = performance(pred,"auc")
  auc = as.numeric(auc@y.values)
  
  get.measure <- function(pred, measure.name='auc') {
    perf = performance(pred,measure.name)
    m <- unlist(slot(perf, "y.values"))
    m
  }
  err = mean(get.measure(pred, 'err'))
  accuracy = 1-err
  cat('accuracy=',accuracy,'\n')
  precision = mean(get.measure(pred, 'prec'),na.rm=T)
  recall = mean(get.measure(pred, 'rec'),na.rm=T)
  fscore = mean(get.measure(pred, 'f'),na.rm=T)
  cat('error=',err,'precision=',precision,'recall=',recall,'f-score',fscore,'\n')
  auc = get.measure(pred, 'auc')
  cat('auc=',auc,'\n')
  
  if (evaluate) return (perf)
  else
    return(rbind(
      error = err,
      accuracy = 1-err,
      precision = precision,
      recall = recall,
      fscore = fscore,
      auc = auc))
}

```



