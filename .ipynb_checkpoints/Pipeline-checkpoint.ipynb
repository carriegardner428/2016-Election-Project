{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import re\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_stops(obs):\n",
    "    stops = set(stopwords.words('english'))\n",
    "    tokens = obs.apply(lambda x: [item for item in x if item not in stops])\n",
    "    print(str(type(tokens)))\n",
    "    return tokens\n",
    "\n",
    "def preprocess(df, remove_stopwords=True):\n",
    "    obs = df.text.str.lower()\n",
    "    obs = obs.str.replace(r'https?:\\/\\/.*[\\r\\n]*', '') # remove http(s) links\n",
    "    obs = obs.str.replace(r'@[A-Za-z0-9]+', '') # remove mentions\n",
    "    obs = obs.str.strip()\n",
    "    obs = obs.str.strip('\"\"')\n",
    "    obs = obs.apply(nltk.word_tokenize)\n",
    "    if (remove_stopwords):\n",
    "        obs = remove_stops(obs)\n",
    "    obs = obs.str.join(' ')\n",
    "    tweets['text'] = obs\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>there is one on my train too .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>rt : the `` life of the mother '' argument for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>broken toes and fracture ... .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>its been a tough one no doubt ... its been a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>rt : fact check : saying `` how stupid is our ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID                                               text\n",
       "0       6                     there is one on my train too .\n",
       "1       9  rt : the `` life of the mother '' argument for...\n",
       "2      11                     broken toes and fracture ... .\n",
       "3      27  its been a tough one no doubt ... its been a t...\n",
       "4      51  rt : fact check : saying `` how stupid is our ..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('tweets_by_user.csv')\n",
    "preprocess(tweets, remove_stopwords=False)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1866, 4)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('users.csv')\n",
    "df = pd.merge(tweets, users, on='userID')\n",
    "\n",
    "df.head(5)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>text</th>\n",
       "      <th>state_code</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>i was pessimistic until right now but ketel wa...</td>\n",
       "      <td>AK</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53</td>\n",
       "      <td>study isaiah , the book jesus quoted most , wi...</td>\n",
       "      <td>AK</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73</td>\n",
       "      <td>paid family leave is a critical economic issue...</td>\n",
       "      <td>AK</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>78</td>\n",
       "      <td>rt : so true and i do n't know either . at lea...</td>\n",
       "      <td>AK</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td># debatenight</td>\n",
       "      <td>AZ</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156</td>\n",
       "      <td>rt : hillary loves her father , a life long re...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>180</td>\n",
       "      <td>i 'm obviously one of the political geeks watc...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>193</td>\n",
       "      <td>underwood 2016rt : holy shit , he just defende...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>196</td>\n",
       "      <td>rt : trump is so out of touch he does n't even...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>216</td>\n",
       "      <td>rt : is hillary calling for sensitivity traini...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>226</td>\n",
       "      <td>rt : they say 100m people are watching these #...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>236</td>\n",
       "      <td>readying 4 the debate with in # tempe # pinkco...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>239</td>\n",
       "      <td>rt : i have an endless amount of joy knowing t...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>240</td>\n",
       "      <td>ask # trump to take off his jacket and tie and...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>244</td>\n",
       "      <td>if this is not the year , when will american s...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID                                               text state_code party\n",
       "5       52  i was pessimistic until right now but ketel wa...         AK     D\n",
       "6       53  study isaiah , the book jesus quoted most , wi...         AK     I\n",
       "8       73  paid family leave is a critical economic issue...         AK     D\n",
       "10      78  rt : so true and i do n't know either . at lea...         AK     I\n",
       "12     113                                      # debatenight         AZ     I\n",
       "16     156  rt : hillary loves her father , a life long re...         AZ     R\n",
       "19     180  i 'm obviously one of the political geeks watc...         AZ     R\n",
       "20     193  underwood 2016rt : holy shit , he just defende...         AZ     I\n",
       "21     196  rt : trump is so out of touch he does n't even...         AZ     R\n",
       "24     216  rt : is hillary calling for sensitivity traini...         AZ     I\n",
       "25     226  rt : they say 100m people are watching these #...         AZ     R\n",
       "26     236  readying 4 the debate with in # tempe # pinkco...         AZ     D\n",
       "27     239  rt : i have an endless amount of joy knowing t...         AZ     D\n",
       "28     240  ask # trump to take off his jacket and tie and...         AZ     D\n",
       "29     244  if this is not the year , when will american s...         AZ     I"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['union', 'classifier']\n",
      "parameters:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       1.00      0.66      0.80       436\n",
      "          G       0.00      0.00      0.00         0\n",
      "          L       0.00      0.00      0.00         0\n",
      "          O       0.00      0.00      0.00         0\n",
      "          R       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.99      0.66      0.79       437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lsa', TruncatedSVD()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__stop_words': (None, 'english'),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'lsa__n_components': (100, 250, 350)\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "class DataFrameColumnExtracter(TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    def get_params(self):\n",
    "        return None\n",
    "    \n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, observations):\n",
    "        return [{'state': str(state)}\n",
    "                for state in observations]\n",
    "    def get_params(self):\n",
    "        return None\n",
    "\n",
    "features = Pipeline([\n",
    "        ('union', FeatureUnion([\n",
    "                    ('dtm', Pipeline([\n",
    "                                ('tfidf', TfidfVectorizer(stop_words=None)),\n",
    "                                ('lsa', TruncatedSVD(n_components=100))\n",
    "                            ])),\n",
    "                    ('state', Pipeline([\n",
    "                                ('colSelector', DataFrameColumnExtracter(column='state_code')),\n",
    "                                ('state', TextStats())\n",
    "                                ])\n",
    "                     )\n",
    "                ])),\n",
    "        ('classifier', LinearSVC())\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['party'], test_size=0.33)\n",
    "print(\"Performing feature union...\")\n",
    "print(\"feature union:\", [name for name, _ in features.steps])\n",
    "print(\"parameters:\")\n",
    "# print(parameters)\n",
    "t0 = time()\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_predictions = pipeline.predict(X_test)\n",
    "print(classification_report(y_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'lsa', 'clf']\n",
      "parameters:\n",
      "{'lsa__n_components': (100, 250, 350), 'tfidf__max_df': (0.5, 0.75, 1.0), 'tfidf__stop_words': (None, 'english'), 'tfidf__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-8)]: Done 108 out of 108 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 611.698s\n",
      "\n",
      "Best score: 0.489\n",
      "Best parameters set:\n",
      "\tlsa__n_components: 250\n",
      "\ttfidf__max_df: 0.5\n",
      "\ttfidf__ngram_range: (1, 1)\n",
      "\ttfidf__stop_words: None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lsa', TruncatedSVD()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__stop_words': (None, 'english'),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'lsa__n_components': (100, 250, 350)\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-8, verbose=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['party'], test_size=0.33)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Independents and test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>text</th>\n",
       "      <th>state_code</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>i was pessimistic until right now but ketel wa...</td>\n",
       "      <td>AK</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73</td>\n",
       "      <td>paid family leave is a critical economic issue...</td>\n",
       "      <td>AK</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156</td>\n",
       "      <td>rt : hillary loves her father , a life long re...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>180</td>\n",
       "      <td>i 'm obviously one of the political geeks watc...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>196</td>\n",
       "      <td>rt : trump is so out of touch he does n't even...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID                                               text state_code party\n",
       "5       52  i was pessimistic until right now but ketel wa...         AK     D\n",
       "8       73  paid family leave is a critical economic issue...         AK     D\n",
       "16     156  rt : hillary loves her father , a life long re...         AZ     R\n",
       "19     180  i 'm obviously one of the political geeks watc...         AZ     R\n",
       "21     196  rt : trump is so out of touch he does n't even...         AZ     R"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.party != 'I']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 4)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'lsa', 'clf']\n",
      "parameters:\n",
      "{'lsa__n_components': (25, 50, 100), 'tfidf__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-8)]: Done  18 out of  18 | elapsed:   16.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 16.691s\n",
      "\n",
      "Best score: 0.663\n",
      "Best parameters set:\n",
      "\tlsa__n_components: 100\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lsa', TruncatedSVD()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    #'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__stop_words': (None, 'english'),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'lsa__n_components': (25, 50, 100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-8, verbose=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['party'], test_size=0.33)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(df['text'], df['party'])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'lsa', 'clf']\n",
      "parameters:\n",
      "{'lsa__n_components': (100, 250, 350), 'tfidf__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-8)]: Done  18 out of  18 | elapsed:   27.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 27.247s\n",
      "\n",
      "Best score: 0.665\n",
      "Best parameters set:\n",
      "\tlsa__n_components: 100\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lsa', TruncatedSVD()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    #'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__stop_words': (None, 'english'),\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'lsa__n_components': (100, 250, 350)\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-8, verbose=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['party'], test_size=0.33)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for SVC.\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  18 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     estimator min_score mean_score max_score  std_score    C  \\\n",
      "10                         SVC  0.960784   0.979984         1  0.0160202    1   \n",
      "11                         SVC  0.921569   0.973856         1  0.0369729   10   \n",
      "4   GradientBoostingClassifier  0.921569    0.96732         1  0.0333269  NaN   \n",
      "5   GradientBoostingClassifier  0.921569    0.96732         1  0.0333269  NaN   \n",
      "8       RandomForestClassifier  0.921569    0.96732         1  0.0333269  NaN   \n",
      "9       RandomForestClassifier  0.921569    0.96732         1  0.0333269  NaN   \n",
      "7         ExtraTreesClassifier  0.901961   0.960784         1  0.0423578  NaN   \n",
      "2   GradientBoostingClassifier  0.921569   0.960376  0.980392  0.0274454  NaN   \n",
      "3   GradientBoostingClassifier  0.921569   0.960376  0.980392  0.0274454  NaN   \n",
      "0           AdaBoostClassifier  0.941176   0.959967  0.980392  0.0160514  NaN   \n",
      "1           AdaBoostClassifier  0.941176   0.959967  0.980392  0.0160514  NaN   \n",
      "6         ExtraTreesClassifier  0.901961    0.95384  0.980392  0.0366875  NaN   \n",
      "14                         SVC  0.921569   0.947304  0.979167  0.0239101   10   \n",
      "12                         SVC  0.901961   0.913807    0.9375  0.0167533    1   \n",
      "13                         SVC  0.901961   0.913807    0.9375  0.0167533    1   \n",
      "15                         SVC  0.901961   0.913807    0.9375  0.0167533   10   \n",
      "\n",
      "     gamma  kernel learning_rate n_estimators  \n",
      "10     NaN  linear           NaN          NaN  \n",
      "11     NaN  linear           NaN          NaN  \n",
      "4      NaN     NaN             1           16  \n",
      "5      NaN     NaN             1           32  \n",
      "8      NaN     NaN           NaN           16  \n",
      "9      NaN     NaN           NaN           32  \n",
      "7      NaN     NaN           NaN           32  \n",
      "2      NaN     NaN           0.8           16  \n",
      "3      NaN     NaN           0.8           32  \n",
      "0      NaN     NaN           NaN           16  \n",
      "1      NaN     NaN           NaN           32  \n",
      "6      NaN     NaN           NaN           16  \n",
      "14   0.001     rbf           NaN          NaN  \n",
      "12   0.001     rbf           NaN          NaN  \n",
      "13  0.0001     rbf           NaN          NaN  \n",
      "15  0.0001     rbf           NaN          NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:40: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSearch:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            z = dict(list(params.items()) + list(d.items()))\n",
    "            return pd.Series(z)\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters)\n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier,\n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "search = EstimatorSearch(models, params)\n",
    "search.fit(X_iris, y_iris, scoring=None, n_jobs=-1)\n",
    "\n",
    "print(search.score_summary())\n",
    "#print(summary.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    1.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVC.\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     estimator min_score mean_score max_score   std_score  \\\n",
      "10                         SVC  0.665158   0.665914  0.667426  0.00106896   \n",
      "12                         SVC  0.665158   0.665914  0.667426  0.00106896   \n",
      "13                         SVC  0.665158   0.665914  0.667426  0.00106896   \n",
      "14                         SVC  0.665158   0.665914  0.667426  0.00106896   \n",
      "15                         SVC  0.665158   0.665914  0.667426  0.00106896   \n",
      "7         ExtraTreesClassifier  0.656109   0.659871   0.66287  0.00281259   \n",
      "9       RandomForestClassifier  0.649203   0.654561  0.662896  0.00597345   \n",
      "8       RandomForestClassifier  0.635535   0.648497  0.667421    0.013683   \n",
      "6         ExtraTreesClassifier  0.638009   0.643249  0.649203  0.00459766   \n",
      "11                         SVC  0.585421   0.605397  0.626697   0.0168766   \n",
      "3   GradientBoostingClassifier  0.585421   0.600872  0.622172    0.015563   \n",
      "5   GradientBoostingClassifier  0.583144   0.597096  0.617647   0.0148386   \n",
      "2   GradientBoostingClassifier  0.580866   0.595583  0.608597   0.0113852   \n",
      "1           AdaBoostClassifier   0.52164    0.59394  0.631222   0.0511324   \n",
      "0           AdaBoostClassifier   0.53303   0.589441  0.635747   0.0425386   \n",
      "4   GradientBoostingClassifier  0.556561   0.576744  0.587699   0.0142892   \n",
      "\n",
      "      C   gamma  kernel learning_rate n_estimators  \n",
      "10    1     NaN  linear           NaN          NaN  \n",
      "12    1   0.001     rbf           NaN          NaN  \n",
      "13    1  0.0001     rbf           NaN          NaN  \n",
      "14   10   0.001     rbf           NaN          NaN  \n",
      "15   10  0.0001     rbf           NaN          NaN  \n",
      "7   NaN     NaN     NaN           NaN           32  \n",
      "9   NaN     NaN     NaN           NaN           32  \n",
      "8   NaN     NaN     NaN           NaN           16  \n",
      "6   NaN     NaN     NaN           NaN           16  \n",
      "11   10     NaN  linear           NaN          NaN  \n",
      "3   NaN     NaN     NaN           0.8           32  \n",
      "5   NaN     NaN     NaN             1           32  \n",
      "2   NaN     NaN     NaN           0.8           16  \n",
      "1   NaN     NaN     NaN           NaN           32  \n",
      "0   NaN     NaN     NaN           NaN           16  \n",
      "4   NaN     NaN     NaN             1           16  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.7s finished\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/carrie/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:42: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class EstimatorSearch:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            z = dict(list(params.items()) + list(d.items()))\n",
    "            return pd.Series(z)\n",
    "\n",
    "        rows = [row(k, gsc.cv_validation_scores, gsc.parameters)\n",
    "                     for k in self.keys\n",
    "                     for gsc in self.grid_searches[k].grid_scores_]\n",
    "        df = pd.concat(rows, axis=1).T.sort([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "X = df['text']\n",
    "y = df['party']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "tfidf = TfidfVectorizer(stop_words='english', max_df=1)\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "normalizer = Normalizer(copy=False)\n",
    "\n",
    "pipeline = make_pipeline(tfidf, svd, normalizer)\n",
    "\n",
    "X_train_dtm = pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier,\n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "search = EstimatorSearch(models, params)\n",
    "search.fit(X_train_dtm, y, scoring=None, n_jobs=-1)\n",
    "\n",
    "print(search.score_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
